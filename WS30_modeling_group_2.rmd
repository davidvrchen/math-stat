---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*.

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
# Load the data.
library("ggplot2")
aex = read.csv("data/AEX.csv")
aex$Date = as.Date(aex$Date)
```

# Part I

## 1

### 1.a

```{r}
library(hrbrthemes)


ggplot(aex) +
  geom_line(mapping=aes(x=Date, y=Open, group=1), color = "blue", linetype = "solid", linewidth = .1) +
  geom_line(mapping=aes(x=Date, y=Close, group=1), color = "red", linetype = "solid", linewidth = .1) +
  scale_x_date(date_breaks = "1 year", date_labels =  "%Y") +
  theme_ipsum() + 
  theme(axis.text=element_text(face="bold"),axis.title.x=element_text(face="bold"),axis.title.y=element_text(face="bold"),axis.text.x=element_text(angle=60, hjust=1))
```

We notice a major decline happening around 1998 after a time of unprecedented growth. This crash likely was caused by the Russian financial crisis at the time, which resulted in steep inflation coupled with major loans issued by the IMF, on which they defaulted at that period in time.

Similarly we see the effect of the dot-com bubble in 2000, the effects of 9/11 in 2001/2002.

in 2008 we see the major sub-prime loan crisis, with bad loans being bundled and sold to third parties ad nauseam until defaults finally caught up and collapsed multiple banks.

### 1.b

No.

Prices one day depend on previous day. Furthermore, we can show by comparison of means for two different time sequences that these are highly unlikely to have been from the same underlying distribution.

```{r}
aex_1993_1995 = aex[aex$Date>="1993-01-01" & aex$Date<= "1995-01-01",]
aex_1996_1998 = aex[aex$Date>= "1996-01-01" & aex$Date<="1998-01-01",]

print(paste("1993-1995 Opening Prices mean:", mean(aex_1993_1995$Close), ", sample deviation: " , sd(aex_1993_1995$Close), ", observations: ", length(aex_1993_1995$Close), sep=""))
print(paste("1996-1998 Opening Prices mean:", mean(aex_1996_1998$Close), ", sample deviation: " , sd(aex_1996_1998$Close), ", observations: ", length(aex_1993_1995$Close), sep=""))
```

If the sample deviation at 1993-1995 is 44.56, with a mean of 373,98. It will be very unlikely to then observe a mean from the same distribution of 693,93. (We could add a two-sample comparison of means here)

### 1.c

```{r}
library(ggplot2)
aex$Returns = (aex$Close - aex$Open) / aex$Open

ggplot(aex ) +
  geom_point(mapping=aes(x=Date, y=Returns, group=1), color = "blue", size = 0.05)
```

relevant summaries:

```{r}
aex$Year = format(aex$Date, "%Y")

data <- aex[(aex$Year >= 1993) & (aex$Year <= 1995),]$Returns
length(data)
print(summary(data))
print(paste("SD: ", sd(data)))
hist(aex$Returns, breaks=100)

boxplot(aex$Returns ~ aex$Year)
```
```{r}
aex$Year = format(aex$Date, "%Y")

data <- aex[(aex$Year >= 1996) & (aex$Year <= 1998),]$Returns
length(data)
print(summary(data))
print(paste("SD: ", sd(data)))
hist(aex$Returns, breaks=100)

boxplot(aex$Returns ~ aex$Year)
```

We observe a stable mean for the daily returns year by year, however, variance seems to still be influenced by time.

### 1.d

Due to the unstable variance over time, we cannot assume that these independent days are i.i.d samples from the same distribution. If they were from the same distribution, we would see (nearly) the same amount of variance and mean for all years, not a \~3x difference in some years compared to lower variance years.

## 2

### 2.a

```{r}
aex_2004 = aex[aex$Year == 2004, ]
aex_2006 = aex[aex$Year == 2006, ]

auto_corr <- function(ordered, k) {
  sample_mean <- mean(ordered)
  sample_var <- var(ordered)
  count <- length(ordered)
  first_demeaned <- ordered[1:(count-k)] - sample_mean
  if (k > 0) {
    shifted_demeaned <- ordered[-(1:k)] - sample_mean  
  } else {
    shifted_demeaned <- ordered - sample_mean
  }
  
  return((1/((count-k)*sample_var)) * sum(first_demeaned*shifted_demeaned))
}

acf_2004 = c()
for (k in 0:(length(aex_2004$Returns)-1)) {
  acf_2004 <- append(acf_2004, auto_corr(rev(aex_2004$Returns), k))
}

plot(acf_2004)
builtin_acf_2004 = acf(rev(aex_2004$Returns), lag.max=(length(aex_2004$Returns)-1), plot=FALSE)$acf[]
plot(builtin_acf_2004)

acf_2006 = c()
for (k in 0:(length(aex_2006$Returns)-1)) {
  acf_2006 <- append(acf_2006, auto_corr(rev(aex_2006$Returns), k))
}

plot(acf_2006)
builtin_acf_2006 = acf(rev(aex_2006$Returns), lag.max=(length(aex_2006$Returns)-1), plot=FALSE)$acf[]
plot(builtin_acf_2006)
```

```{r}
guess <- function(ordered, k) {
  sample_mean <- mean(ordered)
  sample_var <- var(ordered)
  count <- length(ordered)
  first_demeaned <- ordered[1:(count-k)] - sample_mean
  if (k > 0) {
    shifted_demeaned <- ordered[-(1:k)] - sample_mean  
  } else {
    shifted_demeaned <- ordered - sample_mean
  }
  
  return((1/((count)*sample_var)) * sum(first_demeaned*shifted_demeaned))
}

gacf_2004 = c()
for (k in 0:(length(aex_2004$Returns)-1)) {
  gacf_2004 <- append(gacf_2004, guess(rev(aex_2004$Returns), k))
}

gacf_2006 = c()
for (k in 0:(length(aex_2006$Returns)-1)) {
  gacf_2006 <- append(gacf_2006, guess(rev(aex_2006$Returns), k))
}

plot(gacf_2004)
plot(gacf_2006)
```

```{r}
library("car")

hist(aex_2004$Returns, breaks=20)
hist(aex_2006$Returns, breaks=20)

qqPlot(aex_2004$Returns)
qqPlot((aex_2006$Returns))
qqPlot(aex$Returns)

plot(density(aex_2004$Returns))
plot(density(aex_2006$Returns))

boxplot(aex_2004$Returns)
boxplot(aex_2006$Returns)
```

2b: looks beautiful, not normal tho

look at snp500 preprocessing, in general for univariate data heavy-tail to normal transform exists, not sure if useful however2

```{r}
v_mm_est <- function(data) {
  second_moment_expected <- mean(data^2)
  v_mm <- -2*second_moment_expected/(1-second_moment_expected)
  return(v_mm)
}

est <- v_mm_est(aex_2004$Returns - mean(aex_2004$Returns))
est
```
```{r}
library(LaplacesDemon)
library(dplyr)
library(MASS)
```


```{r}
returns_2004 <- aex_2004$Returns

params_2004 = fitdistr(returns_2004, "t")
df_2004 =params_2004$estimate[3]
mu_2004 = params_2004$estimate[1]
sd_2004 = params_2004$estimate[2]




x_2004 <- seq(min(returns_2004), max(returns_2004), length=length(returns_2004)-1)


fun_2004 <- dst(x_2004, mu=mu_2004, sigma=sd_2004, nu=df_2004)


hist(returns_2004, prob=TRUE, breaks=20)

lines(x_2004, fun_2004, col=2,lwd=2)
```
fitdistr uses maximum likelihood estimation. The optimization is done using the optim function in r.
This is based on Nelder-Mead, quasi-Newton and conjugate-gradient algorithms

```{r}
returns_2006 <- aex_2006$Returns

params_2006 = fitdistr(returns_2006, "t")
df_2006 =params_2006$estimate[3]
mu_2006 = params_2006$estimate[1]
sd_2006 = params_2006$estimate[2]

library(dplyr)
library(report)
report::cite_packages()


x_2006 <- seq(min(returns_2006), max(returns_2006), length=length(returns_2006)-1)


fun_2006 <- dst(x_2006, mu=mu_2006, sigma=sd_2006, nu=df_2006)


hist(returns_2006, prob=TRUE, breaks=20)

lines(x_2006, fun_2006, col=2,lwd=2)

```


```{r}

VaR_2004 = qst(0.01, mu=params_2004$estimate[1], sigma=params_2004$estimate[2], nu=params_2004$estimate[3])
VaR_2006 = qst(0.01, mu=params_2006$estimate[1], sigma=params_2006$estimate[2], nu=params_2006$estimate[3])

VaR_2004
VaR_2006

```



```{r}
quantile(aex_2004$Returns, probs=0.01)
quantile(aex_2006$Returns, probs=0.01)
```
```{r}

mean_2004 = mean(aex_2004$Returns) 
var_2004 = var(aex_2004$Returns)
sd_2004 = sd(aex_2004$Returns)
left_2004 = mean_2004 + qnorm(0.025)*sd_2004/sqrt(length(aex_2004))

right_2004 = mean_2004 + qnorm(1-0.025)*sd_2004/sqrt(length(aex_2004))
left_2004
mean_2004
right_2004

```
The mean is normally distributed.
```{r}
hist(aex_2004$Returns, prob=TRUE, breaks=20)

abline(v=left_2004,col='red', lwd=3, lty='dashed')
abline(v=mean_2004,col='red', lwd=3)
abline(v=right_2004,col='red', lwd=3, lty='dashed')
```

```{r}
mean_2006 = mean(aex_2006$Returns) 
var_2006 = var(aex_2006$Returns)
sd_2006 = sd(aex_2006$Returns)
left_2006 = mean_2006 + qnorm(0.025)*sd_2006/sqrt(length(aex_2006))

right_2006 = mean_2006 + qnorm(1-0.025)*sd_2006/sqrt(length(aex_2006))
left_2006
mean_2006
right_2006
```

```{r}
hist(aex_2006$Returns, prob=TRUE, breaks=20)

abline(v=left_2006,col='red', lwd=3, lty='dashed')
abline(v=mean_2006,col='red', lwd=3)
abline(v=right_2006,col='red', lwd=3, lty='dashed')
```

